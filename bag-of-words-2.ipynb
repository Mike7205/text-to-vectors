{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text classification of clickbait headlines\n",
    "## Iteration 2: consolidating the feature columns\n",
    "\n",
    "Count vectorisation turns every token into a column, including variants of the same word with grammatically different forms. It also makes a huge number of columns, some of which might only be non-zero for one or two documents. Consolidating columns with the same meaning and removing unhelpful columns can improve model performance.\n",
    "\n",
    "## Load in dependencies and data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "from support_functions import apply_string_cleaning, train_text_classification_model, generate_predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Read in clickbait data\n",
    "clickbait_train = pd.read_csv(\"data/clickbait_train.csv\", sep=\"\\t\", header=0)\n",
    "clickbait_val = pd.read_csv(\"data/clickbait_val.csv\", sep=\"\\t\", header=0)\n",
    "clickbait_test = pd.read_csv(\"data/clickbait_test.csv\", sep=\"\\t\", header=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Consolidate feature columns\n",
    "\n",
    "We have a lot of feature columns (more than 17K). As we saw in the previous notebook, the feature matrix is also very sparse. There are a few things we can do to tidy it up:\n",
    "* Lemmatisation: this is where we take words that mean the same thing but have the same grammatical form and reduce them all down to the same base form, or lemma (cat, cats -> cat; is, am, are -> be).\n",
    "* Removing stop words: this is where we remove very common words that usually don't have semantic meaning from the feature set.\n",
    "* Keeping only the top n words: we should try to avoid having words in the model that only occur once, as the model cannot use them to detect patterns and therefore they don't add anything to a model's learning.\n",
    "\n",
    "## Lemmatise the text\n",
    "To get started, we'll lemmatise the text using Spacy. We run the EN model over each of the texts, and extract the lemmas for each token."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def lemmatise_text(texts: pd.Series):\n",
    "    lemmatised_texts = []\n",
    "    for doc in nlp.pipe(texts):\n",
    "        lemmatised_texts.append(\" \".join([token.lemma_ for token in doc]))\n",
    "    return pd.Series(lemmatised_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "clickbait_train[\"text_lemmatised\"] = apply_string_cleaning(lemmatise_text(clickbait_train[\"text\"], nlp))\n",
    "clickbait_val[\"text_lemmatised\"] = apply_string_cleaning(lemmatise_text(clickbait_val[\"text\"], nlp))\n",
    "clickbait_test[\"text_lemmatised\"] = apply_string_cleaning(lemmatise_text(clickbait_test[\"text\"], nlp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create count vectoriser which removes stop words and keeps top n vocabulary\n",
    "\n",
    "Here we'll repeat what we did in the previous notebook, but this time we'll ask the count vectoriser to:\n",
    "* Remove stop words: we use the `stop_words = \"english\"` argument;\n",
    "* Keep only the top n most frequent terms: we use the `max_features` argument. I've chosen to set this to 6000 words as I did a prior analysis which showed that this is the cut-off for 3 or more occurrences in the corpus."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "CountVectorizer(max_features=6000, stop_words='english')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_features=6000, stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=6000, stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidyCountVectoriser = CountVectorizer(stop_words=\"english\", max_features=6000)\n",
    "tidyCountVectoriser.fit(clickbait_train[\"text_lemmatised\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_train_tidy = tidyCountVectoriser.transform(clickbait_train[\"text_lemmatised\"]).toarray()\n",
    "X_val_tidy = tidyCountVectoriser.transform(clickbait_val[\"text_lemmatised\"]).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train our simple model\n",
    "\n",
    "We're going to train the same model we did last time, with just one adjustment to account for the change in vocabulary size."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 0.6307 - accuracy: 0.8649 - val_loss: 0.5631 - val_accuracy: 0.9341\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.5087 - accuracy: 0.9511 - val_loss: 0.4683 - val_accuracy: 0.9389\n"
     ]
    }
   ],
   "source": [
    "tidy_model = train_text_classification_model(\n",
    "    X_train_tidy,\n",
    "    clickbait_train[\"label\"].to_numpy(),\n",
    "    X_val_tidy,\n",
    "    clickbait_val[\"label\"].to_numpy(),\n",
    "    X_train_tidy.shape[1],\n",
    "    2,\n",
    "    64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step\n",
      "col_0   0.0   1.0\n",
      "row_0            \n",
      "0      2961   243\n",
      "1       148  3048\n"
     ]
    }
   ],
   "source": [
    "clickbait_val[\"tidy_pred\"] = generate_predictions(tidy_model, X_val_tidy, clickbait_val[\"label\"].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It turns out our accuracy has gone down! After doing a bit of digging, it turns out the issue is the stopword removal. When we examine the texts that the model misclassified, it's clear that the stopwords actually give clickbait titles a lot of their meaning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def filter_stopwords(row):\n",
    "    return \" \".join([w for w in row.split() if w not in ENGLISH_STOP_WORDS])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "clickbait_val[\"text_lemmatised_no_stopwords\"] = clickbait_val[\"text_lemmatised\"].apply(lambda x: filter_stopwords(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  text  \\\n30   The Iconic Beatles Ashram In Rishikesh Is Once...   \n49   This Body Cam Footage Shows A Vehicle Plow Int...   \n83   Photographer Gregory Crewdson Releases Hauntin...   \n104  We Found Out Who The BABE Was Sitting Behind J...   \n109                     Are You More Target Or Walmart   \n190  17 Things Vegetarians In The South Have To Dea...   \n283  What's Your Stance On These Unspoken Rules For...   \n292  Which Newly Revealed Wizard School Should You ...   \n359                        What's Your Personal Slogan   \n383    Stephanie Mills Destroyed Us In NBC's \"The Wiz\"   \n\n                          text_lemmatised_no_stopwords  \n30         iconic beatles ashram rishikesh open public  \n49          body cam footage vehicle plow cop car head  \n83   photographer gregory crewdson releases hauntin...  \n104                    babe sit jake tapper gop debate  \n109                                     target walmart  \n190                       thing vegetarians south deal  \n283                      stance unspoken rules society  \n292            newly reveal wizard school study abroad  \n359                                    personal slogan  \n383                    stephanie mills destroy nbc wiz  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_lemmatised_no_stopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30</th>\n      <td>The Iconic Beatles Ashram In Rishikesh Is Once...</td>\n      <td>iconic beatles ashram rishikesh open public</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>This Body Cam Footage Shows A Vehicle Plow Int...</td>\n      <td>body cam footage vehicle plow cop car head</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>Photographer Gregory Crewdson Releases Hauntin...</td>\n      <td>photographer gregory crewdson releases hauntin...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>We Found Out Who The BABE Was Sitting Behind J...</td>\n      <td>babe sit jake tapper gop debate</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>Are You More Target Or Walmart</td>\n      <td>target walmart</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>17 Things Vegetarians In The South Have To Dea...</td>\n      <td>thing vegetarians south deal</td>\n    </tr>\n    <tr>\n      <th>283</th>\n      <td>What's Your Stance On These Unspoken Rules For...</td>\n      <td>stance unspoken rules society</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>Which Newly Revealed Wizard School Should You ...</td>\n      <td>newly reveal wizard school study abroad</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>What's Your Personal Slogan</td>\n      <td>personal slogan</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>Stephanie Mills Destroyed Us In NBC's \"The Wiz\"</td>\n      <td>stephanie mills destroy nbc wiz</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickbait_val.loc[\n",
    "    (clickbait_val[\"label\"] == 1) & (clickbait_val[\"tidy_pred\"] == 0),\n",
    "    [\"text\", \"text_lemmatised_no_stopwords\"]][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  \\\n0   People Keep Making Huge Facebook Chats With Pe...   \n6   Phoebe Buffay Is Supposed To Die On October 15...   \n8   The #Blessed Life Of Kaskade, EDM's Voice Of R...   \n10  Can You Guess The Christmas Movie From Its Ama...   \n11            16 Questions We Have About Kylie Jenner   \n12  19 Texts All Twentysomethings Have Sent Their Dad   \n15  20 Signs That Definitely Have A Hilarious Stor...   \n16  12 Things You Probably Didn't Know About The \"...   \n17    Americans Try Canadian Candy For The First Time   \n18  Who Would Be Your \"Harry Potter\" Best Friend B...   \n\n                 text_lemmatised_no_stopwords  \n0      people make huge facebook chats people  \n6           phoebe buffay suppose die october  \n8       blessed life kaskade edm voice reason  \n10        guess christmas movie amazon review  \n11                      question kylie jenner  \n12              text twentysomething send dad  \n15            sign definitely hilarious story  \n16     thing probably know shadowhunters cast  \n17          americans try canadian candy time  \n18  harry potter good friend base zodiac sign  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>text_lemmatised_no_stopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>People Keep Making Huge Facebook Chats With Pe...</td>\n      <td>people make huge facebook chats people</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Phoebe Buffay Is Supposed To Die On October 15...</td>\n      <td>phoebe buffay suppose die october</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The #Blessed Life Of Kaskade, EDM's Voice Of R...</td>\n      <td>blessed life kaskade edm voice reason</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Can You Guess The Christmas Movie From Its Ama...</td>\n      <td>guess christmas movie amazon review</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>16 Questions We Have About Kylie Jenner</td>\n      <td>question kylie jenner</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>19 Texts All Twentysomethings Have Sent Their Dad</td>\n      <td>text twentysomething send dad</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>20 Signs That Definitely Have A Hilarious Stor...</td>\n      <td>sign definitely hilarious story</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>12 Things You Probably Didn't Know About The \"...</td>\n      <td>thing probably know shadowhunters cast</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Americans Try Canadian Candy For The First Time</td>\n      <td>americans try canadian candy time</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Who Would Be Your \"Harry Potter\" Best Friend B...</td>\n      <td>harry potter good friend base zodiac sign</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clickbait_val.loc[\n",
    "    (clickbait_val[\"label\"] == 1) & (clickbait_val[\"tidy_pred\"] == 1),\n",
    "    [\"text\", \"text_lemmatised_no_stopwords\"]][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train a model with the stopwords included\n",
    "\n",
    "Let's confirm our guess and retrain the same model with the stopwords included. We'll need to create a new vectoriser which does not remove the stopwords."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "CountVectorizer(max_features=6000)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_features=6000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=6000)</pre></div></div></div></div></div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tidySwCountVectoriser = CountVectorizer(max_features=6000)\n",
    "tidySwCountVectoriser.fit(clickbait_train[\"text_lemmatised\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "X_train_tidy_sw = tidySwCountVectoriser.transform(clickbait_train[\"text_lemmatised\"]).toarray()\n",
    "X_val_tidy_sw = tidySwCountVectoriser.transform(clickbait_val[\"text_lemmatised\"]).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 0.5955 - accuracy: 0.8824 - val_loss: 0.4891 - val_accuracy: 0.9583\n",
      "Epoch 2/7\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.4241 - accuracy: 0.9646 - val_loss: 0.3684 - val_accuracy: 0.9628\n",
      "Epoch 3/7\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.3203 - accuracy: 0.9698 - val_loss: 0.2891 - val_accuracy: 0.9655\n",
      "Epoch 4/7\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.2494 - accuracy: 0.9722 - val_loss: 0.2329 - val_accuracy: 0.9669\n",
      "Epoch 5/7\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1983 - accuracy: 0.9745 - val_loss: 0.1919 - val_accuracy: 0.9689\n",
      "Epoch 6/7\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.1606 - accuracy: 0.9767 - val_loss: 0.1616 - val_accuracy: 0.9695\n",
      "Epoch 7/7\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.1324 - accuracy: 0.9783 - val_loss: 0.1392 - val_accuracy: 0.9705\n"
     ]
    }
   ],
   "source": [
    "tidy_sw_model = train_text_classification_model(\n",
    "    X_train_tidy_sw,\n",
    "    clickbait_train[\"label\"].to_numpy(),\n",
    "    X_val_tidy_sw,\n",
    "    clickbait_val[\"label\"].to_numpy(),\n",
    "    X_train_tidy.shape[1],\n",
    "    7,\n",
    "    64\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 1ms/step\n",
      "col_0   0.0   1.0\n",
      "row_0            \n",
      "0      3097   107\n",
      "1        82  3114\n"
     ]
    }
   ],
   "source": [
    "clickbait_val[\"tidy_sw_pred\"] = generate_predictions(tidy_sw_model, X_val_tidy_sw, clickbait_val[\"label\"].to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We're now back to around the same accuracy as with the baseline model. It seems that our lemmatisation and restricting to top n vocabulary haven't improved model fit."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}